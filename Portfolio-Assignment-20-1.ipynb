{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "jjqUzwe969mu",
    "nbgrader": {
     "checksum": "62f7819e52083a254c81c2228bc31591",
     "grade": false,
     "grade_id": "cell-d5c13075b6763d8d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#%pip uninstall protobuf -y\n",
    "#%pip install protobuf==3.20.1\n",
    "\n",
    "# After running the above commands, please restart the kernel BEFORE running the import statements below.\n",
    "\n",
    "# conda install pandas\n",
    "#%pip install tensorflow-macos\n",
    "#%pip install tensorflow-metal\n",
    "#%pip install tensorflow-datasets\n",
    "#%pip install tensorflow\n",
    "#%pip install scikit-learn\n",
    "import pandas                      as pd\n",
    "import tensorflow                  as tf  # type: ignore\n",
    "from   tensorflow              import keras # type: ignore\n",
    "from   sklearn.model_selection import train_test_split\n",
    "\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "OI7tGV857bn0",
    "nbgrader": {
     "checksum": "3f83776f4e0ac502b9e769d736f6c41d",
     "grade": false,
     "grade_id": "cell-c794bfd6201853f8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## IMDB movie reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "TYaoGIaOpo2Z",
    "nbgrader": {
     "checksum": "a801dca45a23e220901889d822f5ebe6",
     "grade": false,
     "grade_id": "cell-fcfffc985f66b628",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Retrieving and preparing the Data\n",
    "\n",
    "We will work with the IMDb movie reviews data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e8cf131872ebd7d8399460943470bbe2",
     "grade": false,
     "grade_id": "cell-20a04a21a94fc74e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# question 1\n",
    "# Read in the IMDB Dataset into \"data\". Do not set an index column\n",
    "data = pd.read_csv('files/IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2ab187fcf006207c13e1220389ed1fb4",
     "grade": false,
     "grade_id": "cell-106c15bf7fc4e150",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "72caedc853058ef311a7d160aa7f0b9a",
     "grade": false,
     "grade_id": "cell-c5da00bb8d244d49",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# question 2\n",
    "# Replace all \"negative\" and \"positive\" sentiment values with 0 and 1 respectively.\n",
    "# You can use a simple logical operator instead of label encoding.\n",
    "data['sentiment'] = data['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "bf7d4c869d3b0584629fbf89a1aa00d2",
     "grade": false,
     "grade_id": "cell-fb60c3ad8cffa7d5",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# question 3\n",
    "# Get the dependent data and assign to y\n",
    "y = data['sentiment']   \n",
    "print(y[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0edcaeb4d67e532613270d5df55b4acf",
     "grade": false,
     "grade_id": "cell-841ced4ea0dcaf2f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# question 4\n",
    "# Split the X data (data['review']) and y data into X_train, X_test, y_train, and y_test\n",
    "# With a test size of 0.2 and a random_state of 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['review'], y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "4RK7K2ZCqTb4",
    "nbgrader": {
     "checksum": "e3ab5d9602a766b48cce4d38187f6322",
     "grade": false,
     "grade_id": "cell-2744a959d2f8f369",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "Train samples: {X_train.shape[0]}\n",
    "Test samples: {X_test.shape[0]}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "deletable": false,
    "editable": false,
    "id": "wZtI-YRqTRrg",
    "nbgrader": {
     "checksum": "712aac7799944741784d78205b4c4d50",
     "grade": false,
     "grade_id": "cell-8b669b1b85e4f6aa",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "outputId": "01963e47-907e-4ed2-a17d-2299070d3729"
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "OzLguIWdeB-5",
    "nbgrader": {
     "checksum": "0b30a67f0a9a62fae89dd8d046c70438",
     "grade": false,
     "grade_id": "cell-8b95ac774030229c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Inspect the frequence of each sentiment in the traning dataset (it is balanced!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "1dVkRgPIuneP",
    "nbgrader": {
     "checksum": "256c996847f61b8dc7c6e046d1198a9c",
     "grade": false,
     "grade_id": "cell-e3bd86db55a92c1b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "outputId": "71478b47-0750-4dc1-ec2e-9fa8a296fad0"
   },
   "outputs": [],
   "source": [
    "# question 5\n",
    "# Calculate the training data's frequency and assign the output to \"frequency\"\n",
    "frequency = y_train.value_counts() / y_train.shape[0]\n",
    "print(frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "sia5LebDeuDM",
    "nbgrader": {
     "checksum": "3696f28f069bdf94d5ca55a10f13b6f5",
     "grade": false,
     "grade_id": "cell-d9c0261312c36fad",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# cell 6\n",
    "# Let's turn the target into a dummy vector\n",
    "y_train = pd.get_dummies(y_train).to_numpy()\n",
    "y_test  = pd.get_dummies(y_test).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4d6cc03e20ea5c8a9ed9e4dd65cb22c9",
     "grade": false,
     "grade_id": "cell-12af49dffe46d4f2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "p4ktfnOWeX-x",
    "nbgrader": {
     "checksum": "53482d2ab677e371636a3b13c495a694",
     "grade": false,
     "grade_id": "cell-8fdd5bd24c5b1aa8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Unigram Multi-hot Encoding Baseline\n",
    "\n",
    "Next, let us see the performance of a neural net that is trained from the scratch using multi-hot encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "h48xnYwyXLWK",
    "nbgrader": {
     "checksum": "7f66cef5156075bb4fe7dc9d70a97df0",
     "grade": false,
     "grade_id": "cell-e9277fc1e87a127a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization # type: ignore\n",
    "\n",
    "# Set the maximum number of tokens to 2412. \n",
    "# Also set up our Text Vectorization layer using multi-hot encoding\n",
    "max_tokens      = 2412\n",
    "text_vectorization = TextVectorization(max_tokens  = max_tokens, \n",
    "                                    output_mode = 'multi_hot') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "1cfb54eadaf4db959ada980f108ab13a",
     "grade": false,
     "grade_id": "cell-d866880efca5c5ba",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# The vocabulary that will be indexed is given by the text corpus on our train dataset\n",
    "text_vectorization.adapt(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "jO96Ho9WXVtb",
    "nbgrader": {
     "checksum": "c6cf40ac2eac47ef2c41e0a33e7046c6",
     "grade": false,
     "grade_id": "cell-8173b8e7c6ffe8a9",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Question 7\n",
    "# We vectorize our input\n",
    "X_train = text_vectorization(X_train)\n",
    "X_test  = text_vectorization(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "366225b8fe209f21675f420d258e870a",
     "grade": false,
     "grade_id": "cell-d039bb02c0b80a1a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Question 8\n",
    "# Now create your model. start with 32 dense relu layers, a dropout layer of 0.5, and a final softmax layer\n",
    "inputs  = keras.Input(shape=(max_tokens, ))\n",
    "x       = keras.layers.Dense(32, activation=\"relu\")(inputs)\n",
    "x       = keras.layers.Dropout(0.5)(x)\n",
    "outputs = keras.layers.Dense(2, activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "07007d98c76cf4987306051fa690778a",
     "grade": false,
     "grade_id": "cell-bf0c9b489f54a4f1",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Compile your model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "95b5575361496edbb11f0c060a42679a",
     "grade": false,
     "grade_id": "cell-dd0a166873b6f420",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Fit model\n",
    "# Use one-hot encoded y for training and testing\n",
    "model.fit(\n",
    "    x              = X_train, \n",
    "    y              = y_train.astype('float32'), \n",
    "    validation_data= (X_test, \n",
    "                      y_test.astype('float32')),\n",
    "    epochs         = 5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d38d17e24c54522e921010e1dabfe031",
     "grade": false,
     "grade_id": "cell-19919983da9eb5f0",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Question 9\n",
    "# Evaluate your model. You should be able to get your model to 85% at this point\n",
    "# Use one-hot encoded y for evaluation as well\n",
    "model.evaluate(x=X_test, y=y_test.astype('float32'))[1] > 0.85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "hlSWRoTGqn7Y",
    "nbgrader": {
     "checksum": "f24877faf0501bb073b82d4907dc36b9",
     "grade": false,
     "grade_id": "cell-70a2245e1fd4ffbd",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Extend Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "zr2zmxTRquGw",
    "nbgrader": {
     "checksum": "46be15ce582c83eb9c3e1016c3657f2f",
     "grade": false,
     "grade_id": "cell-a3569eb3279dc7b1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Let's create more complex models to increase the accuracy on our test sample. Try combining different models by changing:\n",
    "- Number of hidden units\n",
    "- Adding another hidden layer.\n",
    "- Changing the number of epochs.\n",
    "- Using bigrams instead of unigrams.\n",
    "\n",
    "To guide your search for the best parameters, note how the accuracy changes on both train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "72tQJQOWqrxG",
    "nbgrader": {
     "checksum": "bc6d313f23848cca133da79089f248fa",
     "grade": false,
     "grade_id": "cell-d123d80f6d95e712",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "embedding_dim = 64\n",
    "hidden_units  = 32\n",
    "num_classes   = y_train.shape[1]  # Use y_train, which is one-hot encoded\n",
    "model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(max_tokens,)),  # Use max_tokens as input shape\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "cifar = tf.keras.datasets.cifar100\n",
    "(x_train, y_train), (x_test, y_test) = cifar.load_data()\n",
    "model = tf.keras.applications.ResNet50(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_shape=(32, 32, 3),\n",
    "    classes=100,)\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "model.compile(optimizer=\"adam\", loss=loss_fn, metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=64)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
